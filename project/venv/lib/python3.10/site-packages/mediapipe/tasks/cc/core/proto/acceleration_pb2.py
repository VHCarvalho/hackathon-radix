# -*- coding: utf-8 -*-
# Generated by the protocol buffer compiler.  DO NOT EDIT!
# source: mediapipe/tasks/cc/core/proto/acceleration.proto

import sys
_b=sys.version_info[0]<3 and (lambda x:x) or (lambda x:x.encode('latin1'))
from google.protobuf import descriptor as _descriptor
from google.protobuf import message as _message
from google.protobuf import reflection as _reflection
from google.protobuf import symbol_database as _symbol_database
# @@protoc_insertion_point(imports)

_sym_db = _symbol_database.Default()


from mediapipe.calculators.tensor import inference_calculator_pb2 as mediapipe_dot_calculators_dot_tensor_dot_inference__calculator__pb2


DESCRIPTOR = _descriptor.FileDescriptor(
  name='mediapipe/tasks/cc/core/proto/acceleration.proto',
  package='mediapipe.tasks.core.proto',
  syntax='proto2',
  serialized_options=_b('\n\037com.google.mediapipe.tasks.coreB\021AccelerationProto'),
  serialized_pb=_b('\n0mediapipe/tasks/cc/core/proto/acceleration.proto\x12\x1amediapipe.tasks.core.proto\x1a\x37mediapipe/calculators/tensor/inference_calculator.proto\"\xa8\x01\n\x0c\x41\x63\x63\x65leration\x12I\n\x07xnnpack\x18\x01 \x01(\x0b\x32\x36.mediapipe.InferenceCalculatorOptions.Delegate.XnnpackH\x00\x12\x41\n\x03gpu\x18\x02 \x01(\x0b\x32\x32.mediapipe.InferenceCalculatorOptions.Delegate.GpuH\x00\x42\n\n\x08\x64\x65legateB4\n\x1f\x63om.google.mediapipe.tasks.coreB\x11\x41\x63\x63\x65lerationProto')
  ,
  dependencies=[mediapipe_dot_calculators_dot_tensor_dot_inference__calculator__pb2.DESCRIPTOR,])




_ACCELERATION = _descriptor.Descriptor(
  name='Acceleration',
  full_name='mediapipe.tasks.core.proto.Acceleration',
  filename=None,
  file=DESCRIPTOR,
  containing_type=None,
  fields=[
    _descriptor.FieldDescriptor(
      name='xnnpack', full_name='mediapipe.tasks.core.proto.Acceleration.xnnpack', index=0,
      number=1, type=11, cpp_type=10, label=1,
      has_default_value=False, default_value=None,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='gpu', full_name='mediapipe.tasks.core.proto.Acceleration.gpu', index=1,
      number=2, type=11, cpp_type=10, label=1,
      has_default_value=False, default_value=None,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
  ],
  extensions=[
  ],
  nested_types=[],
  enum_types=[
  ],
  serialized_options=None,
  is_extendable=False,
  syntax='proto2',
  extension_ranges=[],
  oneofs=[
    _descriptor.OneofDescriptor(
      name='delegate', full_name='mediapipe.tasks.core.proto.Acceleration.delegate',
      index=0, containing_type=None, fields=[]),
  ],
  serialized_start=138,
  serialized_end=306,
)

_ACCELERATION.fields_by_name['xnnpack'].message_type = mediapipe_dot_calculators_dot_tensor_dot_inference__calculator__pb2._INFERENCECALCULATOROPTIONS_DELEGATE_XNNPACK
_ACCELERATION.fields_by_name['gpu'].message_type = mediapipe_dot_calculators_dot_tensor_dot_inference__calculator__pb2._INFERENCECALCULATOROPTIONS_DELEGATE_GPU
_ACCELERATION.oneofs_by_name['delegate'].fields.append(
  _ACCELERATION.fields_by_name['xnnpack'])
_ACCELERATION.fields_by_name['xnnpack'].containing_oneof = _ACCELERATION.oneofs_by_name['delegate']
_ACCELERATION.oneofs_by_name['delegate'].fields.append(
  _ACCELERATION.fields_by_name['gpu'])
_ACCELERATION.fields_by_name['gpu'].containing_oneof = _ACCELERATION.oneofs_by_name['delegate']
DESCRIPTOR.message_types_by_name['Acceleration'] = _ACCELERATION
_sym_db.RegisterFileDescriptor(DESCRIPTOR)

Acceleration = _reflection.GeneratedProtocolMessageType('Acceleration', (_message.Message,), dict(
  DESCRIPTOR = _ACCELERATION,
  __module__ = 'mediapipe.tasks.cc.core.proto.acceleration_pb2'
  # @@protoc_insertion_point(class_scope:mediapipe.tasks.core.proto.Acceleration)
  ))
_sym_db.RegisterMessage(Acceleration)


DESCRIPTOR._options = None
# @@protoc_insertion_point(module_scope)
